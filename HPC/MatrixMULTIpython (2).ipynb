{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sz3wFQ5U23zb"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from numba import cuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@cuda.jit\n",
        "def matrixMul(A, B, C):\n",
        "    row, col = cuda.grid(2)\n",
        "    if row < N and col < K:\n",
        "        sum_val = 0.0\n",
        "        for i in range(M):\n",
        "            sum_val += A[row, i] * B[i, col]\n",
        "        C[row, col] = sum_val"
      ],
      "metadata": {
        "id": "B_OtFzu03Dki"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = int(input(\"enter the size of matrix: \"))\n",
        "\n",
        "M = N = K = size\n",
        "\n",
        "# A = np.random.randn(N, M).astype(np.float32)\n",
        "A = np.random.randint(2, size=(N, M)).astype(np.float32)\n",
        "# B = np.random.randn(M, K).astype(np.float32)\n",
        "B = np.random.randint(2, size=(N, M)).astype(np.float32)\n",
        "C = np.zeros((N, K), dtype=np.float32)\n",
        "\n",
        "d_A = cuda.to_device(A)\n",
        "d_B = cuda.to_device(B)\n",
        "d_C = cuda.to_device(C)\n",
        "\n",
        "block_dim = (32, 32)\n",
        "grid_dim = ((N + block_dim[0] - 1) // block_dim[0], (K + block_dim[1] - 1) // block_dim[1])\n",
        "\n",
        "matrixMul[grid_dim, block_dim](d_A, d_B, d_C)\n",
        "\n",
        "C = d_C.copy_to_host()\n",
        "\n",
        "print(C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L587IPv93DnE",
        "outputId": "4951d740-111a-4bad-a136-177cf2720129"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter the size of matrix: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3. 2. 1. 1. 1. 2. 0. 2. 1. 1.]\n",
            " [6. 5. 4. 6. 4. 2. 3. 5. 4. 5.]\n",
            " [3. 3. 3. 4. 2. 1. 3. 4. 3. 4.]\n",
            " [4. 3. 1. 2. 2. 2. 1. 4. 3. 1.]\n",
            " [5. 3. 2. 2. 2. 3. 2. 3. 3. 3.]\n",
            " [5. 4. 1. 2. 3. 2. 2. 3. 4. 2.]\n",
            " [5. 2. 1. 4. 2. 2. 1. 3. 3. 2.]\n",
            " [3. 3. 1. 3. 1. 1. 1. 3. 3. 1.]\n",
            " [4. 3. 3. 4. 2. 2. 3. 2. 3. 4.]\n",
            " [3. 3. 3. 3. 2. 2. 0. 3. 2. 2.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Certainly! Here's an explanation of the code line by line:\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# import numpy as np\n",
        "# from numba import cuda\n",
        "\n",
        "# @cuda.jit\n",
        "# def matrixMul(A, B, C):\n",
        "#     row, col = cuda.grid(2)\n",
        "#     if row < N and col < K:\n",
        "#         sum_val = 0.0\n",
        "#         for i in range(M):\n",
        "#             sum_val += A[row, i] * B[i, col]\n",
        "#         C[row, col] = sum_val\n",
        "# The code starts by importing necessary libraries: numpy for array operations and cuda from numba for GPU programming.\n",
        "\n",
        "# @cuda.jit is a decorator provided by numba that marks the following function as a CUDA kernel function. It means that this function will be executed on the GPU.\n",
        "\n",
        "# matrixMul is the CUDA kernel function for matrix multiplication. It takes three arguments: A, B, and C, representing the input matrices and the resulting matrix.\n",
        "\n",
        "# row, col = cuda.grid(2) retrieves the thread indices within the 2D grid. Each thread will handle a specific row and column of the resulting matrix.\n",
        "\n",
        "# if row < N and col < K: ensures that the thread is within the valid range of rows and columns. This is necessary when the matrix size is not a multiple of the block size.\n",
        "\n",
        "# sum_val = 0.0 initializes a variable to hold the sum of element-wise products during matrix multiplication.\n",
        "\n",
        "# The following for loop iterates over the range of M, which is the inner dimension of the matrices. It calculates the sum of products of corresponding elements from matrices A and B.\n",
        "\n",
        "# C[row, col] = sum_val assigns the calculated sum to the corresponding element in the resulting matrix C.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# size = int(input(\"enter the size of matrix: \"))\n",
        "# M = N = K = size\n",
        "\n",
        "# A = np.random.randint(2, size=(N, M)).astype(np.float32)\n",
        "# B = np.random.randint(2, size=(N, M)).astype(np.float32)\n",
        "# C = np.zeros((N, K), dtype=np.float32)\n",
        "# size = int(input(\"enter the size of matrix: \")) prompts the user to enter the size of the square matrix.\n",
        "\n",
        "# M = N = K = size assigns the value of size to M, N, and K, making them equal. This ensures that the input matrices A and B have compatible dimensions for multiplication.\n",
        "\n",
        "# A and B are randomly generated matrices with values ranging from 0 to 1. They are created using np.random.randint and cast to np.float32 data type.\n",
        "\n",
        "# C is initialized as a zero-filled matrix of size (N, K) using np.zeros.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# d_A = cuda.to_device(A)\n",
        "# d_B = cuda.to_device(B)\n",
        "# d_C = cuda.to_device(C)\n",
        "# d_A, d_B, and d_C are device arrays created using cuda.to_device from the original arrays A, B, and C. These device arrays reside in GPU memory.\n",
        "# python\n",
        "# Copy code\n",
        "# block_dim = (32, 32)\n",
        "# grid_dim = ((N + block_dim[0] - 1) // block_dim[0], (K + block_dim[1] - 1) // block_dim[1])\n",
        "# block_dim specifies the dimensions of a block of threads. Here, it is set to (32, 32), meaning each block consists of 32x32 threads.\n",
        "\n",
        "# grid_dim specifies the dimensions of the grid of blocks needed to cover the entire matrix. It is calculated based on the matrix size and block dimensions.\n",
        "\n",
        "# python\n",
        "# Copy code\n",
        "# matrixMul[grid_dim, block_dim](d_A, d_B, d_C)\n",
        "# This line launches the CUDA kernel function matrixMul on the GPU. It specifies the grid dimensions (grid_dim) and block dimensions (block_dim), followed by the arguments d_A, d_B, and d_C representing the device arrays.\n",
        "# python\n",
        "# Copy code\n",
        "# C = d_C.copy_to_host()\n",
        "# d_C.copy_to_host() copies the resulting matrix C from GPU memory back to the host (CPU) memory.\n",
        "# python\n",
        "# Copy code\n",
        "# print(C)\n",
        "# Finally, the resulting matrix C is printed.\n",
        "# Overall, this code performs matrix multiplication on the GPU using CUDA. It takes the size of the matrix as input, generates random input matrices A and B, performs the matrix multiplication on the GPU, and prints the resulting matrix C."
      ],
      "metadata": {
        "id": "lIWgbNDS3DrX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9qbROLtx3Dv-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TCWVPxLD3DyU"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}